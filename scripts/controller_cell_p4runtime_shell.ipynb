{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 13:31:46.255019: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-12 13:31:46.753099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-12 13:31:46.753204: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-12 13:31:48.883326: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-12 13:31:48.883637: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-12 13:31:48.883667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from generators.controller_runtime_shell import Controller, P4ProtoTxtParser\n",
    "from generators.evaluation_parser import EvaluationPaser\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded NN model.\n",
      "Loaded RF model.\n",
      "Loaded XGB model.\n",
      "Setup the connection to switch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:StreamChannel error, closing stream\n",
      "CRITICAL:root:P4Runtime RPC error (UNAVAILABLE): Socket closed\n"
     ]
    }
   ],
   "source": [
    "############################################### setup ###############################################\n",
    "p4_prog_name = \"rf_new\"\n",
    "# p4_prog_name = \"temp\"\n",
    "\n",
    "p4_info_path = f\"../p4/build/{p4_prog_name}.p4info.txt\"\n",
    "p4_bin_path = f\"../p4/build/{p4_prog_name}.json\"\n",
    "switch_grpc_addr = \"127.0.0.1:50052\"\n",
    "\n",
    "# ml models paths\n",
    "controller_models_dir = '../outputs/controller_ml/'\n",
    "\n",
    "nn_model_dir = controller_models_dir + 'nn_model/'\n",
    "rf_model_path = controller_models_dir + 'rf_model.pkl'\n",
    "xgb_model_path = controller_models_dir + \"xgb_model.json\"\n",
    "\n",
    "# setup the connection\n",
    "my_controller = Controller(model_nn_dir=nn_model_dir, model_rf_path=rf_model_path, model_xgb_path=xgb_model_path)\n",
    "my_controller.setUp(device_grpc_addr=switch_grpc_addr, \n",
    "                    device_id=0, \n",
    "                    p4_info_path=p4_info_path, \n",
    "                    p4_bin_path=p4_bin_path)\n",
    "\n",
    "# parse the P4 proto text file\n",
    "proto_parser = P4ProtoTxtParser(p4_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### shut down the connection ###############################################\n",
    "my_controller.tearDown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### get features in training dataset ###############################################\n",
    "# ATTENTION: The following features are not in the training dataset, but exists in P4 program\n",
    "#       bidirectional_first_seen_ms\n",
    "#       bidirectional_packets\n",
    "#       splt_direction_1_0\n",
    "#       splt_direction_1_2\n",
    "#       splt_direction_2_0\n",
    "#       splt_direction_3_0\n",
    "#       splt_direction_4_0\n",
    "#       splt_direction_5_0\n",
    "#       splt_direction_6_0\n",
    "#       splt_direction_7_0\n",
    "#       splt_direction_8_0\n",
    "\n",
    "dataset_path = \"../dataset/balanced_wo_time/balanced_wo_time_equal_8/preprocessed_balanced_wo_time_equal_8_merged.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "training_features = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### process packetIn (part 1) ###############################################\n",
    "# pathes\n",
    "flow_length = 8\n",
    "relevant_features_num = 20\n",
    "feature_relevant_serialiazation_path = f\"../outputs/serialization/balanced_wo_time/feature_relevant_balanced_wo_time_equal_{flow_length}_f_{relevant_features_num}_serialized.pkl\"\n",
    "\n",
    "# get header collection\n",
    "pkt_in_header_id2name_dict = proto_parser.get_packet_in_id2name_dict()\n",
    "pkt_in_header_name2id_dict = proto_parser.get_packet_in_name2id_dict()\n",
    "pkt_out_header_list = proto_parser.get_packet_out_header()\n",
    "\n",
    "# # load relevant features\n",
    "# with open(feature_relevant_serialiazation_path, \"rb\") as f:\n",
    "#     relevant_feature_list = pickle.load(f)\n",
    "\n",
    "features_list = ['bidirectional_bytes', 'src2dst_packets', 'src2dst_bytes',\n",
    "       'dst2src_packets', 'dst2src_bytes', 'bidirectional_min_ps',\n",
    "       'bidirectional_mean_ps', 'bidirectional_max_ps', 'src2dst_min_ps',\n",
    "       'src2dst_max_ps', 'dst2src_min_ps', 'dst2src_max_ps',\n",
    "       'bidirectional_syn_packets', 'bidirectional_cwr_packets',\n",
    "       'bidirectional_ece_packets', 'bidirectional_urg_packets',\n",
    "       'bidirectional_ack_packets', 'bidirectional_psh_packets',\n",
    "       'bidirectional_rst_packets', 'bidirectional_fin_packets',\n",
    "       'src2dst_syn_packets', 'src2dst_cwr_packets', 'src2dst_ece_packets',\n",
    "       'src2dst_urg_packets', 'src2dst_ack_packets', 'src2dst_psh_packets',\n",
    "       'src2dst_rst_packets', 'src2dst_fin_packets', 'dst2src_syn_packets',\n",
    "       'dst2src_cwr_packets', 'dst2src_ece_packets', 'dst2src_urg_packets',\n",
    "       'dst2src_ack_packets', 'dst2src_psh_packets', 'dst2src_rst_packets',\n",
    "       'dst2src_fin_packets', 'splt_ps_1', 'splt_ps_2', 'splt_ps_3',\n",
    "       'splt_ps_4', 'splt_ps_5', 'splt_ps_6', 'splt_ps_7', 'splt_ps_8',\n",
    "       'splt_direction_1_1', 'splt_direction_2_1', 'splt_direction_2_2',\n",
    "       'splt_direction_3_1', 'splt_direction_3_2', 'splt_direction_4_1',\n",
    "       'splt_direction_4_2', 'splt_direction_5_1', 'splt_direction_5_2',\n",
    "       'splt_direction_6_1', 'splt_direction_6_2', 'splt_direction_7_1',\n",
    "       'splt_direction_7_2', 'splt_direction_8_1', 'splt_direction_8_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### process packetIn (part 2) ###############################################\n",
    "# sniff the packets from switch\n",
    "pktIn_handler = my_controller.packetIn_handler\n",
    "pktIn_handler.my_sniff(lambda pkt: my_controller.predict_flow(pkt, pkt_in_header_id2name_dict, features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### get the average prediction time for NN, RF, XGB ###############################################\n",
    "number_to_switch = my_controller.get_number_flow_to_switch()\n",
    "avg_prediction_time_nn = my_controller.get_prediction_time_avg_nn()\n",
    "avg_prediction_time_rf = my_controller.get_prediction_time_avg_rf()\n",
    "avg_prediction_time_xgb = my_controller.get_prediction_time_avg_xgb()\n",
    "\n",
    "print(f\"number of flows classified in controller: {number_to_switch}\")\n",
    "print(f\"average prediction time of NN: {avg_prediction_time_nn}\")\n",
    "print(f\"average prediction time of RF: {avg_prediction_time_rf}\")\n",
    "print(f\"average prediction time of XGB: {avg_prediction_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_controller.get_number_flow_to_switch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ save evaluation in csv  ################################################\n",
    "# parameter setting\n",
    "gini_threshold = 0.1\n",
    "timeout_expiration = 1800 # second\n",
    "evaluation_index = 1\n",
    "evaluation_day_list = [\"tuesday\", \"wednesday\", \"thursday\", \"friday\"]\n",
    "# evaluation_day_list = [\"friday\"]\n",
    "\n",
    "# first columns dictionary in csv file\n",
    "parameter_dict = {\n",
    "    \"evaluation_index\": evaluation_index,\n",
    "    \"gini_threshold\": gini_threshold,\n",
    "    \"timeout_expiration\": timeout_expiration\n",
    "}\n",
    "\n",
    "# initialize paths\n",
    "evaluation_file_path_list = []\n",
    "csv_save_path_list = []\n",
    "for day in evaluation_day_list:\n",
    "    evaluation_file_path = f'../evaluation/{day}/{day}_evaluation_index_{evaluation_index}/{day}_txt_gini_{gini_threshold}_{evaluation_index}.txt'\n",
    "    csv_save_path = f'../evaluation/{day}/{day}_csv.csv'\n",
    "    evaluation_file_path_list.append(evaluation_file_path)\n",
    "    csv_save_path_list.append(csv_save_path)\n",
    "\n",
    "# save evaluation in csv file for each dataset\n",
    "evalation_parser = EvaluationPaser()\n",
    "for i, day in enumerate(evaluation_day_list):\n",
    "    evalation_parser.parse_file(evaluation_file_path_list[i])\n",
    "    evalation_parser.save_to_csv(csv_path=csv_save_path_list[i], keep_header=False, dataset_day=day, parameter_dict=parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_save_path_list[3])\n",
    "for column in df.columns:\n",
    "    print(f\"{column}: {df.iloc[0][column]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def show():\n",
    "    print(\"it's thread 1\")\n",
    "\n",
    "def show1():\n",
    "    print(\"it's thread 2\")\n",
    "\n",
    "\n",
    "t1 = threading.Thread(target=show)\n",
    "t2 = threading.Thread(target=show1)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time_p4\n",
    "- 0.004922 (3)\n",
    "- 0.00889596875 (32)\n",
    "- 0.00778157894736842105263157894737 (38)\n",
    "- 0.010970875 (120)\n",
    "- 0.20708834545454546 (495)\n",
    "- 0.1078373282442748 (917)\n",
    "- 0.09084598601102163 (4718)\n",
    "- 0.23016635096735188 (6616)\n",
    "- 0.2307465652053849 (14485)\n",
    "- 0.18141805931414529 (26857)\n",
    "\n",
    "\n",
    "## time_controller\n",
    "- 0.6180241666666666 (18)\n",
    "- 0.40646744117647058823529411764706 (34)\n",
    "- 0.5851153153153152 (222)\n",
    "- 0.6580463358778627 (262)\n",
    "- 0.5068668896103896 (308)\n",
    "- 0.4153190846063455 (851)\n",
    "- 0.6655356756756756 (1591)\n",
    "- 0.6661054379297865 (2763)\n",
    "- 0.5803789624119029 (3831)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
